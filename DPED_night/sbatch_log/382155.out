WARNING:tensorflow:From /itet-stor/ollehman/net_scratch/conda_envs/tencu10/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term

The following parameters will be applied for CNN training:

Batch size: 28
Train size: 2000
Learning rate: 5e-05
Training iterations: 30000
Restore iteration at: 20000

Loss: dped_night
Path to DPED dataset: ../../crops/
Path to VGG-19 network: vgg_pretrained/imagenet-vgg-verydeep-19.mat
Evaluation step: 1000
Run Id: dped_night_loss
Input Images: 3

2021-06-20 00:31:55.493367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-06-20 00:31:55.561482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:04:00.0
2021-06-20 00:31:55.570793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:31:55.761252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-20 00:31:56.045686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-20 00:31:56.658671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-20 00:31:56.990636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-20 00:31:57.186335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-20 00:31:57.789921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-20 00:31:57.797638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-20 00:31:57.799035: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-06-20 00:31:57.828714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599830000 Hz
2021-06-20 00:31:57.829930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5604efbda5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-06-20 00:31:57.830675: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-06-20 00:31:57.834174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:04:00.0
2021-06-20 00:31:57.835023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:31:57.835735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-20 00:31:57.836500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-20 00:31:57.837160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-20 00:31:57.837806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-20 00:31:57.838597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-20 00:31:57.839317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-20 00:31:57.845717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-20 00:31:57.846527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:31:57.996353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-20 00:31:57.997290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-06-20 00:31:57.998187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-06-20 00:31:58.005587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10283 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
2021-06-20 00:31:58.008772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5604f0bfa800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-06-20 00:31:58.009523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
WARNING:tensorflow:From /srv/beegfs02/scratch/hdr_night/data/hdr_night/DPED_night/vgg.py:49: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /itet-stor/ollehman/net_scratch/conda_envs/tencu10/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Restoring Variables from: dped_night_loss/iteration_20000
Initializing variables
Loading validation data...
Validation data was loaded

Loading training data...
Training data was loaded

Training network
2021-06-20 00:41:57.461644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-20 00:41:57.984103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-20 00:42:02.131871: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2021-06-20 00:42:05.872674: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-20 00:42:05.873578: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-20 00:42:07.151285: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-20 00:42:07.151995: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
step 21000 | discriminator accuracy | train: 0.7072, test: 0.6528
step 21000 generator losses | train: 198, val: 165.8 | content: 8.867, color: 2004, texture: -17.31, tv: 0.0008797 | psnr: 16.52, ms-ssim: 0.8492

total train/eval time: 0:25:49.944587
step 22000 | discriminator accuracy | train: 0.6151, test: 0.5909
step 22000 generator losses | train: 161.6, val: 151.3 | content: 8.301, color: 771, texture: -18.75, tv: 0.001132 | psnr: 20.25, ms-ssim: 0.8789

total train/eval time: 0:45:50.518837
2021-06-20 01:37:22.020736: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
step 23000 | discriminator accuracy | train: 0.5971, test: 0.5336
step 23000 generator losses | train: 145.9, val: 141.1 | content: 7.83, color: 650.5, texture: -19.48, tv: 0.001224 | psnr: 20.9, ms-ssim: 0.8854

total train/eval time: 1:05:45.036480
2021-06-20 01:56:43.544757: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
step 24000 | discriminator accuracy | train: 0.6222, test: 0.5058
step 24000 generator losses | train: 138.5, val: 138.2 | content: 7.834, color: 600.1, texture: -22.18, tv: 0.001534 | psnr: 21.25, ms-ssim: 0.8911

total train/eval time: 1:25:06.554151
2021-06-20 02:16:24.733611: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
step 25000 | discriminator accuracy | train: 0.667, test: 0.4795
step 25000 generator losses | train: 132.1, val: 135.8 | content: 7.873, color: 593.9, texture: -25.45, tv: 0.001809 | psnr: 21.22, ms-ssim: 0.8899

total train/eval time: 1:44:47.839014
2021-06-20 02:35:48.867821: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
step 26000 | discriminator accuracy | train: 0.7274, test: 0.5142
step 26000 generator losses | train: 135.3, val: 131.7 | content: 7.769, color: 604.5, texture: -27.61, tv: 0.001764 | psnr: 21.14, ms-ssim: 0.8885

total train/eval time: 2:04:11.863780
step 27000 | discriminator accuracy | train: 0.7754, test: 0.5032
step 27000 generator losses | train: 133.4, val: 124 | content: 7.769, color: 584, texture: -35.19, tv: 0.00207 | psnr: 21.25, ms-ssim: 0.8897

total train/eval time: 2:23:45.072961
step 28000 | discriminator accuracy | train: 0.8038, test: 0.5173
step 28000 generator losses | train: 127.4, val: 122.8 | content: 7.633, color: 566.7, texture: -33.73, tv: 0.00215 | psnr: 21.31, ms-ssim: 0.8903

total train/eval time: 2:43:10.514162
step 29000 | discriminator accuracy | train: 0.8192, test: 0.5242
step 29000 generator losses | train: 128.7, val: 122 | content: 7.608, color: 565.3, texture: -34.18, tv: 0.002096 | psnr: 21.29, ms-ssim: 0.8895

total train/eval time: 3:02:48.611936
step 30000 | discriminator accuracy | train: 0.8363, test: 0.5394
step 30000 generator losses | train: 128.3, val: 119.3 | content: 7.399, color: 551.9, texture: -32.46, tv: 0.001873 | psnr: 21.43, ms-ssim: 0.8947

total train/eval time: 3:22:13.836312
total train/eval time: 3:26:39.783892
