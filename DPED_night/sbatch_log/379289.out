WARNING:tensorflow:From /itet-stor/ollehman/net_scratch/conda_envs/tencu10/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term

The following parameters will be applied for CNN training:

Batch size: 32
Train size: 5000
Learning rate: 0.0001
Training iterations: 20000
Restore iteration at: 0

Loss: dped
Path to DPED dataset: ../../crops/
Path to VGG-19 network: vgg_pretrained/imagenet-vgg-verydeep-19.mat
Evaluation step: 1000
Run Id: pynet_loss_5000
Input Images: 3

2021-06-14 18:45:12.582913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-06-14 18:45:12.684350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2021-06-14 18:45:12.687254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-14 18:45:12.719219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-14 18:45:12.762385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-14 18:45:12.786964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-14 18:45:12.791942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-14 18:45:12.796391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-14 18:45:12.804372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-14 18:45:12.819748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-14 18:45:12.821023: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-06-14 18:45:12.850714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099875000 Hz
2021-06-14 18:45:12.851973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa6aadb410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-06-14 18:45:12.852933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-06-14 18:45:12.862674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2021-06-14 18:45:12.863506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-14 18:45:12.864405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-14 18:45:12.865257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-14 18:45:12.866057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-14 18:45:12.866982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-14 18:45:12.867966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-14 18:45:12.868911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-14 18:45:12.882719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-14 18:45:12.883591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-14 18:45:13.176343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-14 18:45:13.177297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-06-14 18:45:13.178241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-06-14 18:45:13.192933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)
2021-06-14 18:45:13.196935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa6b961b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-06-14 18:45:13.197872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
WARNING:tensorflow:From /srv/beegfs02/scratch/hdr_night/data/hdr_night/DPED_night/vgg.py:49: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /itet-stor/ollehman/net_scratch/conda_envs/tencu10/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Initializing variables
Loading validation data...
Validation data was loaded

Loading training data...
Training data was loaded

Training network
2021-06-14 19:01:06.067159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-14 19:01:07.457124: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2021-06-14 19:01:07.588477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-14 19:01:08.495157: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.173989: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.256038: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.626308: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.652641: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.741196: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.750288: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.765786: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.768387: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-06-14 19:01:09.825329: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
step 0 generator losses | train: 7.938, val: 8764 | content: 11.5, color: 8526, tv: 6.183e-06 | psnr: 10.19, ms-ssim: 0.3931

current train/eval time: 0:16:28.449562
step 1000 generator losses | train: 1323, val: 1033 | content: 11.57, color: 795.7, tv: 0.0005922 | psnr: 19.49, ms-ssim: 0.8265

current train/eval time: 0:45:14.821105
step 2000 generator losses | train: 899.2, val: 942.5 | content: 11.27, color: 712.2, tv: 0.0006261 | psnr: 20.09, ms-ssim: 0.8437

current train/eval time: 1:14:31.167046
step 3000 generator losses | train: 837.3, val: 749.3 | content: 10.88, color: 527.4, tv: 0.0005813 | psnr: 20.97, ms-ssim: 0.8607

current train/eval time: 1:43:31.095646
step 4000 generator losses | train: 812.7, val: 781.7 | content: 10.37, color: 570.1, tv: 0.0005779 | psnr: 20.97, ms-ssim: 0.8671

current train/eval time: 2:12:35.424193
step 5000 generator losses | train: 776.3, val: 777 | content: 9.92, color: 574.6, tv: 0.0006093 | psnr: 21.06, ms-ssim: 0.8747

current train/eval time: 2:41:44.878295
step 6000 generator losses | train: 779.8, val: 739.5 | content: 9.781, color: 540, tv: 0.0007093 | psnr: 21.32, ms-ssim: 0.8805

current train/eval time: 3:09:56.483197
step 7000 generator losses | train: 754.8, val: 711.4 | content: 9.427, color: 519.1, tv: 0.0006826 | psnr: 21.49, ms-ssim: 0.8829

current train/eval time: 3:38:47.870435
step 8000 generator losses | train: 746, val: 705 | content: 9.414, color: 512.9, tv: 0.0007479 | psnr: 21.42, ms-ssim: 0.879

current train/eval time: 4:07:19.749354
step 9000 generator losses | train: 742.3, val: 741.2 | content: 9.056, color: 556.4, tv: 0.0007572 | psnr: 21.39, ms-ssim: 0.8855

current train/eval time: 4:35:14.253725
step 10000 generator losses | train: 736.5, val: 818.4 | content: 9.076, color: 633.3, tv: 0.0008093 | psnr: 21.11, ms-ssim: 0.8851

current train/eval time: 5:03:44.566545
step 11000 generator losses | train: 708.6, val: 741.3 | content: 8.856, color: 560.6, tv: 0.0008458 | psnr: 21.41, ms-ssim: 0.8886

current train/eval time: 5:32:42.545885
step 12000 generator losses | train: 721.4, val: 648.4 | content: 8.75, color: 469.9, tv: 0.0007608 | psnr: 21.87, ms-ssim: 0.8869

current train/eval time: 6:01:46.841271
step 13000 generator losses | train: 694.9, val: 666.7 | content: 8.8, color: 487.2, tv: 0.0009391 | psnr: 21.78, ms-ssim: 0.8878

current train/eval time: 6:30:45.237098
step 14000 generator losses | train: 686.3, val: 685.6 | content: 8.656, color: 509, tv: 0.0009439 | psnr: 21.69, ms-ssim: 0.8903

current train/eval time: 6:59:05.948911
step 15000 generator losses | train: 664.5, val: 643.9 | content: 8.559, color: 469.3, tv: 0.0009441 | psnr: 21.89, ms-ssim: 0.8895

current train/eval time: 7:27:56.534632
step 16000 generator losses | train: 675.2, val: 694.8 | content: 8.532, color: 520.6, tv: 0.0009224 | psnr: 21.63, ms-ssim: 0.8887

current train/eval time: 7:57:17.607628
step 17000 generator losses | train: 675, val: 660.1 | content: 8.546, color: 485.7, tv: 0.001006 | psnr: 21.8, ms-ssim: 0.8902

current train/eval time: 8:25:53.856901
step 18000 generator losses | train: 671.2, val: 675.8 | content: 8.435, color: 503.6, tv: 0.001004 | psnr: 21.73, ms-ssim: 0.8883

current train/eval time: 8:54:01.829019
step 19000 generator losses | train: 648.5, val: 655.8 | content: 8.423, color: 484, tv: 0.001004 | psnr: 21.86, ms-ssim: 0.8906

current train/eval time: 9:21:51.305976
step 20000 generator losses | train: 643.3, val: 661 | content: 8.295, color: 491.6, tv: 0.0009679 | psnr: 21.77, ms-ssim: 0.8888

current train/eval time: 9:50:03.284690
total train/eval time: 10:00:12.774237
